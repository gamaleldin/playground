{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel level rnn on MNIST\n",
    "This is a simple exercise to use RNN model for mnist classification. The model scan MNIST images pixel by pixel to classify the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define experiment params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 1  # input dimensionality is 1 (1 pixel at a time)\n",
    "T = 28*28  # times is the total number of pixels\n",
    "num_classes = 10 \n",
    "num_units = 64  # number of units in network\n",
    "max_iter = 10000\n",
    "init_lr = 0.001  # initial learning rate\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_provider(object):\n",
    "  \"\"\"MNIST data provider.\"\"\"\n",
    "  def __init__(self, data_directory, split=\"train\"):\n",
    "    mnist_data = mnist.input_data.read_data_sets(data_directory, one_hot=True)\n",
    "    if split == \"train\":\n",
    "      self.mnist_data = mnist_data.train\n",
    "    elif split == \"valid\":\n",
    "      self.mnist_data = mnist_data.validation\n",
    "    elif split == \"test\":\n",
    "      self.mnist_data = mnist_data.test\n",
    "\n",
    "  def next_batch(self, batch_size):\n",
    "    images, one_hot_labels = self.mnist_data.next_batch(batch_size)\n",
    "    images = np.reshape(images, [-1, 28, 28, 1], order='C')\n",
    "    return images, one_hot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "  \"\"\"Class for RNN cell.\n",
    "  \n",
    "  Args:\n",
    "    weights: dictionary of weights as tensorflow variables.\n",
    "    biases: dictionary of biases as tensorflow variables.\n",
    "    outputs: rnn output pre logit (list of size number of time steps).\n",
    "    state: final rnn state.\n",
    "    cell: tensorflow cell obbject\n",
    "    logits_list: list of logits at each time point.\n",
    "  \"\"\"\n",
    "  def __init__(self, inputs, num_units, num_classes, activation=tf.nn.tanh):\n",
    "    \"\"\"Init function.\n",
    "    \n",
    "    Inputs:\n",
    "      inputs: list of lenght time steps for rnn inputs.\n",
    "      num_units: number of network units.\n",
    "      num_classes: network output classes.\n",
    "      activation: activation function to use for cell (default tanh).\n",
    "    \"\"\"\n",
    "    \n",
    "    self.weights = {}\n",
    "    self.biases = {}\n",
    "    with tf.variable_scope(\"rnn\"):\n",
    "      with tf.variable_scope(\"internal\"):\n",
    "        self.cell = tf.nn.rnn_cell.GRUCell(\n",
    "          num_units=num_units, activation=activation)\n",
    "        \n",
    "        self.outputs, self.state = tf.contrib.rnn.static_rnn(\n",
    "          cell=self.cell, inputs=inputs, dtype=tf.float32)\n",
    "      with tf.variable_scope(\"output\"):\n",
    "        self.weights[\"out\"] = tf.get_variable(name=\"w\",\n",
    "                        shape=(num_units, num_classes),\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        \n",
    "        self.biases[\"out\"] = tf.get_variable(name=\"b\",\n",
    "                        shape=(num_classes),\n",
    "                        initializer=tf.zeros_initializer())\n",
    "    for v in self.cell.trainable_variables:\n",
    "      name = v.name\n",
    "      if \"gates/kernel\" in name:\n",
    "        self.weights[\"gates\"] = v\n",
    "      elif \"gates/bias\" in name:\n",
    "        self.biases[\"gates\"] = v\n",
    "\n",
    "      elif \"candidate/kernel\" in name:\n",
    "        self.weights[\"candidate\"] = v\n",
    "      elif \"candidate/bias\" in name:\n",
    "        self.biases[\"candidate\"] = v\n",
    "\n",
    "    # compute logits at each time step\n",
    "    self.logits_list = []\n",
    "    for output in self.outputs:\n",
    "      self.logits_list.append(\n",
    "        tf.matmul(output, self.weights[\"out\"]) + self.biases[\"out\"]) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-650099426339>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/Users/gamal/git_local_repo/playground/data/mnist\"\n",
    "data_provider_train = mnist_provider(data_dir, split='train')\n",
    "data_provider_valid = mnist_provider(data_dir, split='valid')\n",
    "data_provider_test = mnist_provider(data_dir, split='test')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "  x = tf.placeholder(dtype=tf.float32, shape=(None, T, in_dim))\n",
    "  one_hot_labels = tf.placeholder(dtype=tf.float32, shape=(None, num_classes))\n",
    "  # convert in put to a list of len number of time points\n",
    "  x_t = tf.unstack(x, T, 1)\n",
    "  \n",
    "  # model\n",
    "  rnn_model = RNN(inputs=x_t, num_units=num_units, num_classes=num_classes)\n",
    "  logits = rnn_model.logits_list[-1]\n",
    "  \n",
    "  # accuracy metric\n",
    "  top1_op = tf.nn.in_top_k(logits, tf.argmax(one_hot_labels, 1), 1)\n",
    "  accuracy = tf.reduce_mean(tf.cast(top1_op, dtype=tf.float32))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                               labels=one_hot_labels)\n",
    "  )\n",
    "  opt = tf.train.AdamOptimizer(learning_rate=init_lr)\n",
    "  \n",
    "  train_op = opt.minimize(loss)\n",
    "  \n",
    "  init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: (train loss: 2.303) (train accuracy: 0.105)\n",
      "iter 50: (train loss: 2.280) (train accuracy: 0.123)\n",
      "iter 100: (train loss: 2.303) (train accuracy: 0.076)\n",
      "iter 150: (train loss: 2.299) (train accuracy: 0.127)\n",
      "iter 200: (train loss: 2.305) (train accuracy: 0.096)\n",
      "iter 250: (train loss: 2.301) (train accuracy: 0.123)\n",
      "iter 300: (train loss: 2.300) (train accuracy: 0.121)\n",
      "iter 350: (train loss: 2.302) (train accuracy: 0.111)\n",
      "iter 400: (train loss: 2.303) (train accuracy: 0.100)\n",
      "iter 450: (train loss: 2.304) (train accuracy: 0.111)\n",
      "iter 500: (train loss: 2.304) (train accuracy: 0.090)\n",
      "iter 550: (train loss: 2.304) (train accuracy: 0.094)\n",
      "iter 600: (train loss: 2.301) (train accuracy: 0.129)\n",
      "iter 650: (train loss: 2.298) (train accuracy: 0.125)\n",
      "iter 700: (train loss: 2.301) (train accuracy: 0.119)\n",
      "iter 750: (train loss: 2.302) (train accuracy: 0.107)\n",
      "iter 800: (train loss: 2.303) (train accuracy: 0.158)\n",
      "iter 850: (train loss: 2.299) (train accuracy: 0.102)\n",
      "iter 900: (train loss: 2.290) (train accuracy: 0.109)\n",
      "iter 950: (train loss: 2.298) (train accuracy: 0.100)\n",
      "iter 1000: (train loss: 2.300) (train accuracy: 0.129)\n",
      "iter 1050: (train loss: 2.256) (train accuracy: 0.152)\n",
      "iter 1100: (train loss: 1.844) (train accuracy: 0.213)\n",
      "iter 1150: (train loss: 1.770) (train accuracy: 0.297)\n",
      "iter 1200: (train loss: 1.714) (train accuracy: 0.324)\n",
      "iter 1250: (train loss: 1.477) (train accuracy: 0.420)\n",
      "iter 1300: (train loss: 1.455) (train accuracy: 0.412)\n",
      "iter 1350: (train loss: 1.426) (train accuracy: 0.439)\n",
      "iter 1400: (train loss: 1.371) (train accuracy: 0.490)\n",
      "iter 1450: (train loss: 1.335) (train accuracy: 0.453)\n",
      "iter 1500: (train loss: 1.226) (train accuracy: 0.541)\n",
      "iter 1550: (train loss: 1.193) (train accuracy: 0.607)\n",
      "iter 1600: (train loss: 1.087) (train accuracy: 0.641)\n",
      "iter 1650: (train loss: 1.020) (train accuracy: 0.648)\n",
      "iter 1700: (train loss: 0.911) (train accuracy: 0.682)\n",
      "iter 1750: (train loss: 0.836) (train accuracy: 0.713)\n",
      "iter 1800: (train loss: 0.848) (train accuracy: 0.738)\n",
      "iter 1850: (train loss: 0.791) (train accuracy: 0.721)\n",
      "iter 1900: (train loss: 0.717) (train accuracy: 0.764)\n",
      "iter 1950: (train loss: 0.705) (train accuracy: 0.752)\n",
      "iter 2000: (train loss: 0.616) (train accuracy: 0.795)\n",
      "iter 2050: (train loss: 0.611) (train accuracy: 0.787)\n",
      "iter 2100: (train loss: 0.655) (train accuracy: 0.785)\n",
      "iter 2150: (train loss: 0.586) (train accuracy: 0.775)\n",
      "iter 2200: (train loss: 0.610) (train accuracy: 0.787)\n",
      "iter 2250: (train loss: 0.637) (train accuracy: 0.754)\n",
      "iter 2300: (train loss: 0.539) (train accuracy: 0.793)\n",
      "iter 2350: (train loss: 0.599) (train accuracy: 0.771)\n",
      "iter 2400: (train loss: 0.550) (train accuracy: 0.779)\n",
      "iter 2450: (train loss: 0.593) (train accuracy: 0.789)\n",
      "iter 2500: (train loss: 0.523) (train accuracy: 0.809)\n",
      "iter 2550: (train loss: 0.386) (train accuracy: 0.852)\n",
      "iter 2600: (train loss: 0.480) (train accuracy: 0.809)\n",
      "iter 2650: (train loss: 0.438) (train accuracy: 0.830)\n",
      "iter 2700: (train loss: 0.505) (train accuracy: 0.826)\n",
      "iter 2750: (train loss: 0.430) (train accuracy: 0.840)\n",
      "iter 2800: (train loss: 0.509) (train accuracy: 0.824)\n",
      "iter 2850: (train loss: 0.379) (train accuracy: 0.846)\n",
      "iter 2900: (train loss: 0.439) (train accuracy: 0.824)\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for i in xrange(max_iter):\n",
    "      imgs, lbls = data_provider_train.next_batch(\n",
    "        batch_size=batch_size)\n",
    "      _, ls, acc = sess.run(\n",
    "        (train_op, loss, accuracy),\n",
    "        feed_dict={x: imgs.reshape((-1, 28*28, 1)),\n",
    "                   one_hot_labels: lbls}\n",
    "      )\n",
    "      \n",
    "      if i % 50 == 0:\n",
    "        print(\n",
    "          \"iter %d: (train loss: %.3f) (train accuracy: %.3f)\" \n",
    "          %(i, ls, acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
