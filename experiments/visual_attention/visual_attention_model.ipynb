{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple object recognition with visual attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I implement the model from Ba et al. \"Multiple object recognition with visual attention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials import mnist\n",
    "from tensorflow.python.ops import array_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_provider(object):\n",
    "  \"\"\"MNIST data provider.\"\"\"\n",
    "  def __init__(self, data_directory, split=\"train\"):\n",
    "    mnist_data = mnist.input_data.read_data_sets(data_directory, one_hot=True)\n",
    "    if split == \"train\":\n",
    "      self.mnist_data = mnist_data.train\n",
    "    elif split == \"valid\":\n",
    "      self.mnist_data = mnist_data.validation\n",
    "    elif split == \"test\":\n",
    "      self.mnist_data = mnist_data.test\n",
    "\n",
    "  def next_batch(self, batch_size):\n",
    "    images, one_hot_labels = self.mnist_data.next_batch(batch_size)\n",
    "    images = np.reshape(images, [-1, 28, 28, 1], order='C')\n",
    "    return images, one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlimpseNet(object):\n",
    "  \"\"\"Glimpse network.\n",
    "  \n",
    "  \"The glimpse network is a non-linear function that receives the current input image\n",
    "  patch, or glimpse, xn and its location tuple ln , where ln = (xn, yn), as input and \n",
    "  outputs a vector gn\"\n",
    "  \"\"\"\n",
    "  def __init__(self, \n",
    "               layers_size=(\n",
    "                 (3, 3, 1, 64),\n",
    "                 (3, 3, 64, 64),\n",
    "                 (3, 3, 64, 64),\n",
    "                 (16 * 16 * 64, 128)\n",
    "               )):\n",
    "    \"\"\" \n",
    "    \n",
    "    Args:\n",
    "      layers_size: layer sizes (tuple of shape tuples).\n",
    "        default:\n",
    "          layer 1: 3x3 conv, input with 1 color channel, 64 channels output\n",
    "          layer 2: 3x3 conv, 64 channels output\n",
    "          layer 3: 3x3 conv, 64 channels output\n",
    "          layer 4: fully connected, input with size 16x16, output size 128\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    self.params = {}\n",
    "    with tf.variable_scope(\"glimpse_net\"):\n",
    "      self.params[\"W_conv1\"] = tf.get_variable(name=\"W_conv1\", shape=layers_size[0],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_conv1\"] = tf.get_variable(name=\"b_conv1\", shape=layers_size[0][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "      \n",
    "      self.params[\"W_conv2\"] = tf.get_variable(name=\"W_conv2\", shape=layers_size[1],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_conv2\"] = tf.get_variable(name=\"b_conv2\", shape=layers_size[1][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "      \n",
    "      self.params[\"W_conv3\"] = tf.get_variable(name=\"W_conv3\", shape=layers_size[2],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_conv3\"] = tf.get_variable(name=\"b_conv3\", shape=layers_size[2][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "      \n",
    "      \n",
    "      self.params[\"W_fc1\"] = tf.get_variable(name=\"W_fc1\", shape=layers_size[3],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_fc1\"] = tf.get_variable(name=\"b_fc1\", shape=layers_size[3][-1],\n",
    "                          initializer=tf.zeros_initializer())      \n",
    "      \n",
    "      self.params[\"W_loc1\"] = tf.get_variable(name=\"W_loc1\", shape=(2, layers_size[3][-1]),\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_loc1\"] = tf.get_variable(name=\"b_loc1\", shape=layers_size[3][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "    \n",
    "  def build(self, x_l, l, activation=tf.nn.relu):\n",
    "    \"\"\"Build glimpse network based on observation x_l at location l and location l.\"\"\"\n",
    "    endpoints = {}\n",
    "    with tf.name_scope(\"glimpse_net\"):\n",
    "      # image network\n",
    "      # convolutional layer 1\n",
    "      endpoints[\"conv_layer1\"] = activation(\n",
    "        tf.nn.conv2d(\n",
    "          x_l, self.params[\"W_conv1\"], strides=(1, 1, 1, 1), padding='SAME'\n",
    "        ) + self.params[\"b_conv1\"])\n",
    "\n",
    "      # convolutional layer 2\n",
    "      endpoints[\"conv_layer2\"] = activation(\n",
    "        tf.nn.conv2d(\n",
    "          endpoints[\"conv_layer1\"], self.params[\"W_conv2\"], strides=[1, 1, 1, 1], padding='SAME'\n",
    "        ) + self.params[\"b_conv2\"])\n",
    "\n",
    "      # convolutional layer 3\n",
    "      endpoints[\"conv_layer3\"] = activation(\n",
    "        tf.nn.conv2d(\n",
    "          endpoints[\"conv_layer2\"], self.params[\"W_conv3\"], strides=[1, 1, 1, 1], padding='SAME'\n",
    "        ) + self.params[\"b_conv3\"])\n",
    "\n",
    "      endpoints[\"conv_layer3_flattened\"] = tf.reshape(\n",
    "        endpoints[\"conv_layer3\"],\n",
    "        shape=(-1, np.prod(endpoints[\"conv_layer3\"].get_shape().as_list()[1:])))\n",
    "\n",
    "      # fully connected layer\n",
    "      endpoints[\"fc_layer1\"] = activation(\n",
    "        tf.matmul(\n",
    "          endpoints[\"conv_layer3_flattened\"], self.params[\"W_fc1\"]) + self.params[\"b_fc1\"])\n",
    "\n",
    "      # location network\n",
    "      endpoints[\"loc_layer1\"] = activation(\n",
    "        tf.matmul(l, self.params[\"W_loc1\"]) + self.params[\"b_loc1\"]\n",
    "      )\n",
    "\n",
    "      # combined output\n",
    "      g = endpoints[\"fc_layer1\"] * endpoints[\"loc_layer1\"]\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmissionNet(object):\n",
    "  \"\"\"Emission network.\n",
    "  \n",
    "  \"The emission network takes the current state of recurrent network as input and \n",
    "  makes a prediction on where to extract the next image patch for the glimpse network.\"\n",
    "  \n",
    "  \"\"\"\n",
    "  def __init__(self, layers_size=((128, 2),)):\n",
    "    \"\"\" \n",
    "    \n",
    "    Args:\n",
    "      layers_size: layer sizes (tuple of shape tuples).\n",
    "        default:\n",
    "          layer 1: fully connected, input with size 128, output size 2\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    self.params = {}\n",
    "    with tf.variable_scope(\"emission_net\"):\n",
    "      \n",
    "      self.params[\"W_fc1\"] = tf.get_variable(name=\"W_fc1\", shape=layers_size[0],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_fc1\"] = tf.get_variable(name=\"b_fc1\", shape=layers_size[0][-1],\n",
    "                          initializer=tf.zeros_initializer())      \n",
    "    \n",
    "  def build(self, r, activation=tf.nn.relu):\n",
    "    \"\"\"Build emission network based on rnn state r.\"\"\"\n",
    "    endpoints = {}\n",
    "    \n",
    "    with tf.name_scope(\"emission_net\"):\n",
    "      # fully connected layer\n",
    "      endpoints[\"fc_layer1\"] = activation(\n",
    "        tf.matmul(\n",
    "          r, self.params[\"W_fc1\"]) + self.params[\"b_fc1\"])\n",
    "\n",
    "      # normalized location (-1, 1) range. [0, 0] is center.\n",
    "      l = 2 * tf.nn.sigmoid(endpoints[\"fc_layer1\"]) - 1\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextNet(object):\n",
    "  \"\"\"Context network.\n",
    "  \n",
    "  \"The context network provides the initial state for the recurrent network and its\n",
    "  output is used by the emission network to predict the location of the first glimpse. The context\n",
    "  network C(Â·) takes a down-sampled low-resolution version of the whole input image Icoarse and\n",
    "  outputs a fixed length vector cI . The contextual information provides sensible hints on where the\n",
    "  potentially interesting regions are in a given image.\"\n",
    "  \"\"\"\n",
    "  def __init__(self, \n",
    "               layers_size=(\n",
    "                 (3, 3, 1, 64),\n",
    "                 (3, 3, 64, 64),\n",
    "                 (3, 3, 64, 64),\n",
    "                 (16 * 16 * 64, 128)\n",
    "               )):\n",
    "    self.params = {}\n",
    "    with tf.variable_scope(\"context_net\"):\n",
    "      self.params[\"W_conv1\"] = tf.get_variable(name=\"W_conv1\", shape=layers_size[0],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_conv1\"] = tf.get_variable(name=\"b_conv1\", shape=layers_size[0][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "      \n",
    "      self.params[\"W_conv2\"] = tf.get_variable(name=\"W_conv2\", shape=layers_size[1],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_conv2\"] = tf.get_variable(name=\"b_conv2\", shape=layers_size[1][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "      \n",
    "      self.params[\"W_conv3\"] = tf.get_variable(name=\"W_conv3\", shape=layers_size[2],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_conv3\"] = tf.get_variable(name=\"b_conv3\", shape=layers_size[2][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "      \n",
    "      \n",
    "      self.params[\"W_fc1\"] = tf.get_variable(name=\"W_fc1\", shape=layers_size[3],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_fc1\"] = tf.get_variable(name=\"b_fc1\", shape=layers_size[3][-1],\n",
    "                          initializer=tf.zeros_initializer())      \n",
    "\n",
    "  \n",
    "  def build(self, x_coarse, activation=tf.nn.relu):\n",
    "    \"\"\"Build context network.\"\"\"\n",
    "    endpoints = {}\n",
    "    with tf.name_scope(\"context_net\"):\n",
    "      # image network\n",
    "      # convolutional layer 1\n",
    "      endpoints[\"conv_layer1\"] = activation(\n",
    "        tf.nn.conv2d(\n",
    "          x_coarse, self.params[\"W_conv1\"], strides=(1, 1, 1, 1), padding='SAME'\n",
    "        ) + self.params[\"b_conv1\"])\n",
    "\n",
    "      # convolutional layer 2\n",
    "      endpoints[\"conv_layer2\"] = activation(\n",
    "        tf.nn.conv2d(\n",
    "          endpoints[\"conv_layer1\"], self.params[\"W_conv2\"], strides=[1, 1, 1, 1], padding='SAME'\n",
    "        ) + self.params[\"b_conv2\"])\n",
    "\n",
    "      # convolutional layer 3\n",
    "      endpoints[\"conv_layer3\"] = activation(\n",
    "        tf.nn.conv2d(\n",
    "          endpoints[\"conv_layer2\"], self.params[\"W_conv3\"], strides=[1, 1, 1, 1], padding='SAME'\n",
    "        ) + self.params[\"b_conv3\"])\n",
    "\n",
    "      endpoints[\"conv_layer3_flattened\"] = tf.reshape(\n",
    "        endpoints[\"conv_layer3\"],\n",
    "        shape=(-1, np.prod(endpoints[\"conv_layer3\"].get_shape().as_list()[1:])))\n",
    "\n",
    "      # fully connected layer\n",
    "      endpoints[\"fc_layer1\"] = activation(\n",
    "        tf.matmul(\n",
    "          endpoints[\"conv_layer3_flattened\"], self.params[\"W_fc1\"]) + self.params[\"b_fc1\"])\n",
    "      \n",
    "    return endpoints[\"fc_layer1\"]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "data_dir = \"/Users/gamal/git_local_repo/playground/data/mnist\"\n",
    "data_provider_train = mnist_provider(data_dir, split='train')\n",
    "data_provider_valid = mnist_provider(data_dir, split='valid')\n",
    "data_provider_test = mnist_provider(data_dir, split='test')\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "  # input data\n",
    "  images = tf.placeholder(shape=(None, 28, 28, 1), dtype=tf.float32)\n",
    "  \n",
    "  # initialize location\n",
    "  labels = tf.placeholder(shape=(None), dtype=tf.float32)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "  glimpse_size = coarse_size = (16, 16)\n",
    "  C = ContextNet()\n",
    "  images_coarse = tf.image.resize_images(images, coarse_size)\n",
    "  h0 = C.build(images_coarse)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "  E = EmissionNet()\n",
    "  l0 = E.build(h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "  G = GlimpseNet()\n",
    "  images_glimpse0 = tf.image.extract_glimpse(\n",
    "    images,\n",
    "    size=glimpse_size,\n",
    "    offsets=l0,\n",
    "    centered=True,\n",
    "    normalized=True)\n",
    "  g0 = G.build(images_glimpse0, l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "  with tf.Session() as sess:\n",
    "    imgs, lbls = data_provider_train.next_batch(\n",
    "        batch_size=2)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    images_glimpse0_, g0_, l0_ = sess.run((images_glimpse0, g0, l0), feed_dict={images: imgs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,u'location (0.03, 0.00)')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1243ec550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(imgs[0][:, :, 0], cmap=\"gray\")\n",
    "plt.title(\"orginal image\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(images_glimpse0_[0][:, :, 0], cmap=\"gray\")\n",
    "plt.title(\"location (%.2f, %.2f)\" %tuple(l0_[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
