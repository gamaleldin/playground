{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel level rnn on MNIST\n",
    "This is a simple exercise to use RNN model for mnist classification. The model scan MNIST images pixel by pixel to classify the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define experiment params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 1  # input dimensionality is 1 (1 pixel at a time)\n",
    "T = 28*28  # times is the total number of pixels\n",
    "num_classes = 10 \n",
    "num_units = 64  # number of units in network\n",
    "max_iter = 10000\n",
    "init_lr = 0.001  # initial learning rate\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_provider(object):\n",
    "  \"\"\"MNIST data provider.\"\"\"\n",
    "  def __init__(self, data_directory, split=\"train\"):\n",
    "    mnist_data = mnist.input_data.read_data_sets(data_directory, one_hot=True)\n",
    "    if split == \"train\":\n",
    "      self.mnist_data = mnist_data.train\n",
    "    elif split == \"valid\":\n",
    "      self.mnist_data = mnist_data.validation\n",
    "    elif split == \"test\":\n",
    "      self.mnist_data = mnist_data.test\n",
    "\n",
    "  def next_batch(self, batch_size):\n",
    "    images, one_hot_labels = self.mnist_data.next_batch(batch_size)\n",
    "    images = np.reshape(images, [-1, 28, 28, 1], order='C')\n",
    "    return images, one_hot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "  \"\"\"Class for RNN cell.\n",
    "  \n",
    "  Args:\n",
    "    weights: dictionary of weights as tensorflow variables.\n",
    "    biases: dictionary of biases as tensorflow variables.\n",
    "    outputs: rnn output pre logit (list of size number of time steps).\n",
    "    state: final rnn state.\n",
    "    cell: tensorflow cell obbject\n",
    "    logits_list: list of logits at each time point.\n",
    "  \"\"\"\n",
    "  def __init__(self, inputs, num_units, num_classes, activation=tf.nn.tanh):\n",
    "    \"\"\"Init function.\n",
    "    \n",
    "    Inputs:\n",
    "      inputs: list of lenght time steps for rnn inputs.\n",
    "      num_units: number of network units.\n",
    "      num_classes: network output classes.\n",
    "      activation: activation function to use for cell (default tanh).\n",
    "    \"\"\"\n",
    "    \n",
    "    self.weights = {}\n",
    "    self.biases = {}\n",
    "    with tf.variable_scope(\"rnn\"):\n",
    "      with tf.variable_scope(\"internal\"):\n",
    "        self.cell = tf.nn.rnn_cell.GRUCell(\n",
    "          num_units=num_units, activation=activation)\n",
    "        \n",
    "        self.outputs, self.state = tf.contrib.rnn.static_rnn(\n",
    "          cell=self.cell, inputs=inputs, dtype=tf.float32)\n",
    "      with tf.variable_scope(\"output\"):\n",
    "        self.weights[\"out\"] = tf.get_variable(name=\"w\",\n",
    "                        shape=(num_units, num_classes),\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        \n",
    "        self.biases[\"out\"] = tf.get_variable(name=\"b\",\n",
    "                        shape=(num_classes),\n",
    "                        initializer=tf.zeros_initializer())\n",
    "    for v in self.cell.trainable_variables:\n",
    "      name = v.name\n",
    "      if \"gates/kernel\" in name:\n",
    "        self.weights[\"gates\"] = v\n",
    "      elif \"gates/bias\" in name:\n",
    "        self.biases[\"gates\"] = v\n",
    "\n",
    "      elif \"candidate/kernel\" in name:\n",
    "        self.weights[\"candidate\"] = v\n",
    "      elif \"candidate/bias\" in name:\n",
    "        self.biases[\"candidate\"] = v\n",
    "\n",
    "    # compute logits at each time step\n",
    "    self.logits_list = []\n",
    "    for output in self.outputs:\n",
    "      self.logits_list.append(\n",
    "        tf.matmul(output, self.weights[\"out\"]) + self.biases[\"out\"]) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-650099426339>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/Users/gamal/git_local_repo/playground/data/mnist\"\n",
    "data_provider_train = mnist_provider(data_dir, split='train')\n",
    "data_provider_valid = mnist_provider(data_dir, split='valid')\n",
    "data_provider_test = mnist_provider(data_dir, split='test')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "  x = tf.placeholder(dtype=tf.float32, shape=(None, T, in_dim))\n",
    "  one_hot_labels = tf.placeholder(dtype=tf.float32, shape=(None, num_classes))\n",
    "  # convert in put to a list of len number of time points\n",
    "  x_t = tf.unstack(x, T, 1)\n",
    "  \n",
    "  # model\n",
    "  rnn_model = RNN(inputs=x_t, num_units=num_units, num_classes=num_classes)\n",
    "  logits = rnn_model.logits_list[-1]\n",
    "  \n",
    "  # accuracy metric\n",
    "  top1_op = tf.nn.in_top_k(logits, tf.argmax(one_hot_labels, 1), 1)\n",
    "  accuracy = tf.reduce_mean(tf.cast(top1_op, dtype=tf.float32))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                               labels=one_hot_labels)\n",
    "  )\n",
    "  opt = tf.train.AdamOptimizer(learning_rate=init_lr)\n",
    "  \n",
    "  train_op = opt.minimize(loss)\n",
    "  \n",
    "  init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: (train loss: 2.303) (train accuracy: 0.105)\n",
      "iter 50: (train loss: 2.280) (train accuracy: 0.123)\n",
      "iter 100: (train loss: 2.303) (train accuracy: 0.076)\n",
      "iter 150: (train loss: 2.299) (train accuracy: 0.127)\n",
      "iter 200: (train loss: 2.305) (train accuracy: 0.096)\n",
      "iter 250: (train loss: 2.301) (train accuracy: 0.123)\n",
      "iter 300: (train loss: 2.300) (train accuracy: 0.121)\n",
      "iter 350: (train loss: 2.302) (train accuracy: 0.111)\n",
      "iter 400: (train loss: 2.303) (train accuracy: 0.100)\n",
      "iter 450: (train loss: 2.304) (train accuracy: 0.111)\n",
      "iter 500: (train loss: 2.304) (train accuracy: 0.090)\n",
      "iter 550: (train loss: 2.304) (train accuracy: 0.094)\n",
      "iter 600: (train loss: 2.301) (train accuracy: 0.129)\n",
      "iter 650: (train loss: 2.298) (train accuracy: 0.125)\n",
      "iter 700: (train loss: 2.301) (train accuracy: 0.119)\n",
      "iter 750: (train loss: 2.302) (train accuracy: 0.107)\n",
      "iter 800: (train loss: 2.303) (train accuracy: 0.158)\n",
      "iter 850: (train loss: 2.299) (train accuracy: 0.102)\n",
      "iter 900: (train loss: 2.290) (train accuracy: 0.109)\n",
      "iter 950: (train loss: 2.298) (train accuracy: 0.100)\n",
      "iter 1000: (train loss: 2.300) (train accuracy: 0.129)\n",
      "iter 1050: (train loss: 2.256) (train accuracy: 0.152)\n",
      "iter 1100: (train loss: 1.844) (train accuracy: 0.213)\n",
      "iter 1150: (train loss: 1.770) (train accuracy: 0.297)\n",
      "iter 1200: (train loss: 1.714) (train accuracy: 0.324)\n",
      "iter 1250: (train loss: 1.477) (train accuracy: 0.420)\n",
      "iter 1300: (train loss: 1.455) (train accuracy: 0.412)\n",
      "iter 1350: (train loss: 1.426) (train accuracy: 0.439)\n",
      "iter 1400: (train loss: 1.371) (train accuracy: 0.490)\n",
      "iter 1450: (train loss: 1.335) (train accuracy: 0.453)\n",
      "iter 1500: (train loss: 1.226) (train accuracy: 0.541)\n",
      "iter 1550: (train loss: 1.193) (train accuracy: 0.607)\n",
      "iter 1600: (train loss: 1.087) (train accuracy: 0.641)\n",
      "iter 1650: (train loss: 1.020) (train accuracy: 0.648)\n",
      "iter 1700: (train loss: 0.911) (train accuracy: 0.682)\n",
      "iter 1750: (train loss: 0.836) (train accuracy: 0.713)\n",
      "iter 1800: (train loss: 0.848) (train accuracy: 0.738)\n",
      "iter 1850: (train loss: 0.791) (train accuracy: 0.721)\n",
      "iter 1900: (train loss: 0.717) (train accuracy: 0.764)\n",
      "iter 1950: (train loss: 0.705) (train accuracy: 0.752)\n",
      "iter 2000: (train loss: 0.616) (train accuracy: 0.795)\n",
      "iter 2050: (train loss: 0.611) (train accuracy: 0.787)\n",
      "iter 2100: (train loss: 0.655) (train accuracy: 0.785)\n",
      "iter 2150: (train loss: 0.586) (train accuracy: 0.775)\n",
      "iter 2200: (train loss: 0.610) (train accuracy: 0.787)\n",
      "iter 2250: (train loss: 0.637) (train accuracy: 0.754)\n",
      "iter 2300: (train loss: 0.539) (train accuracy: 0.793)\n",
      "iter 2350: (train loss: 0.599) (train accuracy: 0.771)\n",
      "iter 2400: (train loss: 0.550) (train accuracy: 0.779)\n",
      "iter 2450: (train loss: 0.593) (train accuracy: 0.789)\n",
      "iter 2500: (train loss: 0.523) (train accuracy: 0.809)\n",
      "iter 2550: (train loss: 0.386) (train accuracy: 0.852)\n",
      "iter 2600: (train loss: 0.480) (train accuracy: 0.809)\n",
      "iter 2650: (train loss: 0.438) (train accuracy: 0.830)\n",
      "iter 2700: (train loss: 0.505) (train accuracy: 0.826)\n",
      "iter 2750: (train loss: 0.430) (train accuracy: 0.840)\n",
      "iter 2800: (train loss: 0.509) (train accuracy: 0.824)\n",
      "iter 2850: (train loss: 0.379) (train accuracy: 0.846)\n",
      "iter 2900: (train loss: 0.439) (train accuracy: 0.824)\n",
      "iter 2950: (train loss: 0.386) (train accuracy: 0.867)\n",
      "iter 3000: (train loss: 0.408) (train accuracy: 0.846)\n",
      "iter 3050: (train loss: 0.451) (train accuracy: 0.859)\n",
      "iter 3100: (train loss: 0.345) (train accuracy: 0.867)\n",
      "iter 3150: (train loss: 0.290) (train accuracy: 0.893)\n",
      "iter 3200: (train loss: 0.459) (train accuracy: 0.848)\n",
      "iter 3250: (train loss: 0.417) (train accuracy: 0.850)\n",
      "iter 3300: (train loss: 0.420) (train accuracy: 0.865)\n",
      "iter 3350: (train loss: 0.394) (train accuracy: 0.844)\n",
      "iter 3400: (train loss: 0.337) (train accuracy: 0.871)\n",
      "iter 3450: (train loss: 0.426) (train accuracy: 0.848)\n",
      "iter 3500: (train loss: 0.355) (train accuracy: 0.877)\n",
      "iter 3550: (train loss: 0.343) (train accuracy: 0.857)\n",
      "iter 3600: (train loss: 0.342) (train accuracy: 0.885)\n",
      "iter 3650: (train loss: 0.410) (train accuracy: 0.852)\n",
      "iter 3700: (train loss: 0.337) (train accuracy: 0.889)\n",
      "iter 3750: (train loss: 0.365) (train accuracy: 0.875)\n",
      "iter 3800: (train loss: 0.353) (train accuracy: 0.869)\n",
      "iter 3850: (train loss: 0.356) (train accuracy: 0.854)\n",
      "iter 3900: (train loss: 0.340) (train accuracy: 0.887)\n",
      "iter 3950: (train loss: 0.303) (train accuracy: 0.896)\n",
      "iter 4000: (train loss: 0.321) (train accuracy: 0.891)\n",
      "iter 4050: (train loss: 0.372) (train accuracy: 0.887)\n",
      "iter 4100: (train loss: 0.324) (train accuracy: 0.883)\n",
      "iter 4150: (train loss: 0.282) (train accuracy: 0.908)\n",
      "iter 4200: (train loss: 0.221) (train accuracy: 0.922)\n",
      "iter 4250: (train loss: 0.325) (train accuracy: 0.900)\n",
      "iter 4300: (train loss: 0.363) (train accuracy: 0.896)\n",
      "iter 4350: (train loss: 0.287) (train accuracy: 0.900)\n",
      "iter 4400: (train loss: 0.320) (train accuracy: 0.898)\n",
      "iter 4450: (train loss: 0.258) (train accuracy: 0.930)\n",
      "iter 4500: (train loss: 0.338) (train accuracy: 0.887)\n",
      "iter 4550: (train loss: 0.281) (train accuracy: 0.898)\n",
      "iter 4600: (train loss: 0.245) (train accuracy: 0.924)\n",
      "iter 4650: (train loss: 0.196) (train accuracy: 0.938)\n",
      "iter 4700: (train loss: 0.279) (train accuracy: 0.910)\n",
      "iter 4750: (train loss: 0.231) (train accuracy: 0.930)\n",
      "iter 4800: (train loss: 0.259) (train accuracy: 0.928)\n",
      "iter 4850: (train loss: 0.248) (train accuracy: 0.918)\n",
      "iter 4900: (train loss: 0.273) (train accuracy: 0.918)\n",
      "iter 4950: (train loss: 0.240) (train accuracy: 0.922)\n",
      "iter 5000: (train loss: 0.222) (train accuracy: 0.936)\n",
      "iter 5050: (train loss: 0.212) (train accuracy: 0.943)\n",
      "iter 5100: (train loss: 0.204) (train accuracy: 0.953)\n",
      "iter 5150: (train loss: 0.348) (train accuracy: 0.889)\n",
      "iter 5200: (train loss: 0.169) (train accuracy: 0.949)\n",
      "iter 5250: (train loss: 0.195) (train accuracy: 0.939)\n",
      "iter 5300: (train loss: 0.219) (train accuracy: 0.934)\n",
      "iter 5350: (train loss: 0.147) (train accuracy: 0.965)\n",
      "iter 5400: (train loss: 0.168) (train accuracy: 0.943)\n",
      "iter 5450: (train loss: 0.184) (train accuracy: 0.939)\n",
      "iter 5500: (train loss: 0.146) (train accuracy: 0.959)\n",
      "iter 5550: (train loss: 0.137) (train accuracy: 0.959)\n",
      "iter 5600: (train loss: 0.177) (train accuracy: 0.949)\n",
      "iter 5650: (train loss: 0.138) (train accuracy: 0.959)\n",
      "iter 5700: (train loss: 0.164) (train accuracy: 0.949)\n",
      "iter 5750: (train loss: 0.186) (train accuracy: 0.943)\n",
      "iter 5800: (train loss: 0.162) (train accuracy: 0.945)\n",
      "iter 5850: (train loss: 0.138) (train accuracy: 0.961)\n",
      "iter 5900: (train loss: 0.169) (train accuracy: 0.947)\n",
      "iter 5950: (train loss: 0.189) (train accuracy: 0.949)\n",
      "iter 6000: (train loss: 0.150) (train accuracy: 0.959)\n",
      "iter 6050: (train loss: 0.141) (train accuracy: 0.963)\n",
      "iter 6100: (train loss: 0.133) (train accuracy: 0.957)\n",
      "iter 6150: (train loss: 0.116) (train accuracy: 0.969)\n",
      "iter 6200: (train loss: 0.118) (train accuracy: 0.971)\n",
      "iter 6250: (train loss: 0.145) (train accuracy: 0.961)\n",
      "iter 6300: (train loss: 0.113) (train accuracy: 0.969)\n",
      "iter 6350: (train loss: 0.119) (train accuracy: 0.967)\n",
      "iter 6400: (train loss: 0.155) (train accuracy: 0.963)\n",
      "iter 6450: (train loss: 0.072) (train accuracy: 0.977)\n",
      "iter 6500: (train loss: 0.104) (train accuracy: 0.967)\n",
      "iter 6550: (train loss: 0.096) (train accuracy: 0.975)\n",
      "iter 6600: (train loss: 0.098) (train accuracy: 0.961)\n",
      "iter 6650: (train loss: 0.116) (train accuracy: 0.961)\n",
      "iter 6700: (train loss: 0.093) (train accuracy: 0.967)\n",
      "iter 6750: (train loss: 0.184) (train accuracy: 0.949)\n",
      "iter 6800: (train loss: 0.122) (train accuracy: 0.967)\n",
      "iter 6850: (train loss: 0.103) (train accuracy: 0.969)\n",
      "iter 6900: (train loss: 0.151) (train accuracy: 0.957)\n",
      "iter 6950: (train loss: 0.122) (train accuracy: 0.959)\n",
      "iter 7000: (train loss: 0.138) (train accuracy: 0.963)\n",
      "iter 7050: (train loss: 0.107) (train accuracy: 0.967)\n",
      "iter 7100: (train loss: 0.090) (train accuracy: 0.980)\n",
      "iter 7150: (train loss: 0.117) (train accuracy: 0.963)\n",
      "iter 7200: (train loss: 0.118) (train accuracy: 0.969)\n",
      "iter 7250: (train loss: 0.112) (train accuracy: 0.979)\n",
      "iter 7300: (train loss: 0.117) (train accuracy: 0.959)\n",
      "iter 7350: (train loss: 0.092) (train accuracy: 0.971)\n",
      "iter 7400: (train loss: 0.124) (train accuracy: 0.961)\n",
      "iter 7450: (train loss: 0.128) (train accuracy: 0.965)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 7500: (train loss: 0.085) (train accuracy: 0.969)\n",
      "iter 7550: (train loss: 0.087) (train accuracy: 0.980)\n",
      "iter 7600: (train loss: 0.067) (train accuracy: 0.980)\n",
      "iter 7650: (train loss: 0.146) (train accuracy: 0.951)\n",
      "iter 7700: (train loss: 0.109) (train accuracy: 0.967)\n",
      "iter 7750: (train loss: 0.139) (train accuracy: 0.959)\n",
      "iter 7800: (train loss: 0.100) (train accuracy: 0.969)\n",
      "iter 7850: (train loss: 0.091) (train accuracy: 0.975)\n",
      "iter 7900: (train loss: 0.135) (train accuracy: 0.969)\n",
      "iter 7950: (train loss: 0.110) (train accuracy: 0.971)\n",
      "iter 8000: (train loss: 0.117) (train accuracy: 0.963)\n",
      "iter 8050: (train loss: 0.057) (train accuracy: 0.980)\n",
      "iter 8100: (train loss: 0.092) (train accuracy: 0.973)\n",
      "iter 8150: (train loss: 0.086) (train accuracy: 0.979)\n",
      "iter 8200: (train loss: 0.065) (train accuracy: 0.984)\n",
      "iter 8250: (train loss: 0.115) (train accuracy: 0.961)\n",
      "iter 8300: (train loss: 0.076) (train accuracy: 0.979)\n",
      "iter 8350: (train loss: 0.103) (train accuracy: 0.973)\n",
      "iter 8400: (train loss: 0.097) (train accuracy: 0.971)\n",
      "iter 8450: (train loss: 0.099) (train accuracy: 0.973)\n",
      "iter 8500: (train loss: 0.082) (train accuracy: 0.982)\n",
      "iter 8550: (train loss: 0.045) (train accuracy: 0.990)\n",
      "iter 8600: (train loss: 0.069) (train accuracy: 0.977)\n",
      "iter 8650: (train loss: 0.097) (train accuracy: 0.963)\n",
      "iter 8700: (train loss: 0.085) (train accuracy: 0.971)\n",
      "iter 8750: (train loss: 0.105) (train accuracy: 0.971)\n",
      "iter 8800: (train loss: 0.054) (train accuracy: 0.984)\n",
      "iter 8850: (train loss: 0.036) (train accuracy: 0.988)\n",
      "iter 8900: (train loss: 0.062) (train accuracy: 0.982)\n",
      "iter 8950: (train loss: 0.076) (train accuracy: 0.982)\n",
      "iter 9000: (train loss: 0.128) (train accuracy: 0.965)\n",
      "iter 9050: (train loss: 0.063) (train accuracy: 0.982)\n",
      "iter 9100: (train loss: 0.093) (train accuracy: 0.967)\n",
      "iter 9150: (train loss: 0.105) (train accuracy: 0.961)\n",
      "iter 9200: (train loss: 0.083) (train accuracy: 0.975)\n",
      "iter 9250: (train loss: 0.093) (train accuracy: 0.973)\n",
      "iter 9300: (train loss: 0.072) (train accuracy: 0.982)\n",
      "iter 9350: (train loss: 0.100) (train accuracy: 0.971)\n",
      "iter 9400: (train loss: 0.035) (train accuracy: 0.990)\n",
      "iter 9450: (train loss: 0.042) (train accuracy: 0.986)\n",
      "iter 9500: (train loss: 0.079) (train accuracy: 0.971)\n",
      "iter 9550: (train loss: 0.104) (train accuracy: 0.971)\n",
      "iter 9600: (train loss: 0.088) (train accuracy: 0.979)\n",
      "iter 9650: (train loss: 0.066) (train accuracy: 0.979)\n",
      "iter 9700: (train loss: 0.098) (train accuracy: 0.969)\n",
      "iter 9750: (train loss: 0.090) (train accuracy: 0.973)\n",
      "iter 9800: (train loss: 0.099) (train accuracy: 0.971)\n",
      "iter 9850: (train loss: 0.038) (train accuracy: 0.988)\n",
      "iter 9900: (train loss: 0.148) (train accuracy: 0.949)\n",
      "iter 9950: (train loss: 0.071) (train accuracy: 0.982)\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for i in xrange(max_iter):\n",
    "      imgs, lbls = data_provider_train.next_batch(\n",
    "        batch_size=batch_size)\n",
    "      _, ls, acc = sess.run(\n",
    "        (train_op, loss, accuracy),\n",
    "        feed_dict={x: imgs.reshape((-1, 28*28, 1)),\n",
    "                   one_hot_labels: lbls}\n",
    "      )\n",
    "      \n",
    "      if i % 50 == 0:\n",
    "        print(\n",
    "          \"iter %d: (train loss: %.3f) (train accuracy: %.3f)\" \n",
    "          %(i, ls, acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
