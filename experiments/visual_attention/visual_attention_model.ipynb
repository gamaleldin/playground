{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple object recognition with visual attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebbook, I implement the network from Ba et al. \"Multiple object recognition with visual attention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class glimpse_network(object):\n",
    "  \"\"\"Glimpse network\"\"\"\n",
    "  def __init__(self, \n",
    "               layer_size=((5, 5, 3, 32), (5, 5, 32, 64), (5, 5, 64, 32), (28 * 28 * 32, 1024))):\n",
    "    \n",
    "    self.params = {}\n",
    "    with tf.variable_scope(\"glimpse_net\"):\n",
    "      self.params[\"W_conv1\"] = tf.get_variable(name=\"W_conv1\", shape=layer_size[0],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_conv1\"] = tf.get_variable(name=\"b_conv1\", shape=layer_size[0][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "      \n",
    "      self.params[\"W_conv2\"] = tf.get_variable(name=\"W_conv2\", shape=layer_size[1],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_conv2\"] = tf.get_variable(name=\"b_conv2\", shape=layer_size[1][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "      \n",
    "      self.params[\"W_conv3\"] = tf.get_variable(name=\"W_conv3\", shape=layer_size[2],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_conv3\"] = tf.get_variable(name=\"b_conv3\", shape=layer_size[2][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "      \n",
    "      \n",
    "      self.params[\"W_fc1\"] = tf.get_variable(name=\"W_fc1\", shape=layer_size[3],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_fc1\"] = tf.get_variable(name=\"b_fc1\", shape=layer_size[3][-1],\n",
    "                          initializer=tf.zeros_initializer())      \n",
    "      \n",
    "      self.params[\"W_loc1\"] = tf.get_variable(name=\"W_loc1\", shape=(2, layer_size[3][-1]),\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "      self.params[\"b_loc1\"] = tf.get_variable(name=\"b_loc1\", shape=layer_size[3][-1],\n",
    "                          initializer=tf.zeros_initializer())\n",
    "    \n",
    "  def build(self, x, l, activation=tf.nn.relu):\n",
    "    \"\"\"Build glimpse network based on observation x and location l.\"\"\"\n",
    "    endpoints = {}\n",
    "    \n",
    "    # image network\n",
    "    # convolutional layer 1\n",
    "    endpoints[\"conv_layer1\"] = activation(\n",
    "      tf.nn.conv2d(\n",
    "        x, self.params[\"W_conv1\"], strides=(1, 1, 1, 1), padding='SAME'\n",
    "      ) + self.params[\"b_conv1\"])\n",
    "    \n",
    "    # convolutional layer 2\n",
    "    endpoints[\"conv_layer2\"] = activation(\n",
    "      tf.nn.conv2d(\n",
    "        endpoints[\"conv_layer1\"], self.params[\"W_conv2\"], strides=[1, 1, 1, 1], padding='SAME'\n",
    "      ) + self.params[\"b_conv2\"])\n",
    "    \n",
    "    # convolutional layer 3\n",
    "    endpoints[\"conv_layer3\"] = activation(\n",
    "      tf.nn.conv2d(\n",
    "        endpoints[\"conv_layer2\"], self.params[\"W_conv3\"], strides=[1, 1, 1, 1], padding='SAME'\n",
    "      ) + self.params[\"b_conv3\"])\n",
    "    \n",
    "    endpoints[\"conv_layer3_flattened\"] = tf.reshape(\n",
    "      endpoints[\"conv_layer3\"],\n",
    "      shape=(-1, np.prod(endpoints[\"conv_layer3\"].get_shape().as_list()[1:])))\n",
    "        \n",
    "    # fully connected layer\n",
    "    endpoints[\"fc_layer1\"] = activation(\n",
    "      tf.matmul(\n",
    "        endpoints[\"conv_layer3_flattened\"], self.params[\"W_fc1\"]) + self.params[\"b_fc1\"])\n",
    "    \n",
    "    # location network\n",
    "    endpoints[\"loc_layer1\"] = activation(\n",
    "      tf.matmul(l, self.params[\"W_loc1\"]) + self.params[\"b_loc1\"]\n",
    "    )\n",
    "    \n",
    "    # combined output\n",
    "    g = endpoints[\"fc_layer1\"] * endpoints[\"loc_layer1\"]\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
