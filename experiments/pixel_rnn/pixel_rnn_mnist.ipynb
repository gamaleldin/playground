{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel level rnn on MNIST\n",
    "This is a simple exercise to use RNN model for mnist classification. The model scan MNIST images pixel by pixel to classify the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials import mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define experiment params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 1  # input dimensionality is 1 (1 pixel at a time)\n",
    "T = 28*28  # times is the total number of pixels\n",
    "num_classes = 10 \n",
    "num_units = 100  # number of units in network\n",
    "max_iter = 50000\n",
    "init_lr = 0.001  # initial learning rate\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_provider(object):\n",
    "  \"\"\"MNIST data provider.\"\"\"\n",
    "  def __init__(self, data_directory, split=\"train\"):\n",
    "    mnist_data = mnist.input_data.read_data_sets(data_directory, one_hot=True)\n",
    "    if split == \"train\":\n",
    "      self.mnist_data = mnist_data.train\n",
    "    elif split == \"valid\":\n",
    "      self.mnist_data = mnist_data.validation\n",
    "    elif split == \"test\":\n",
    "      self.mnist_data = mnist_data.test\n",
    "\n",
    "  def next_batch(self, batch_size):\n",
    "    images, one_hot_labels = self.mnist_data.next_batch(batch_size)\n",
    "    images = np.reshape(images, [-1, 28, 28, 1], order='C')\n",
    "    return images, one_hot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "  \"\"\"Class for RNN cell.\n",
    "  \n",
    "  Args:\n",
    "    weights: dictionary of weights as tensorflow variables.\n",
    "    biases: dictionary of biases as tensorflow variables.\n",
    "    outputs: rnn output pre logit (list of size number of time steps).\n",
    "    state: final rnn state.\n",
    "    cell: tensorflow cell obbject\n",
    "    logits_list: list of logits at each time point.\n",
    "  \"\"\"\n",
    "  def __init__(self, inputs, num_units, num_classes, activation=tf.nn.tanh):\n",
    "    \"\"\"Init function.\n",
    "    \n",
    "    Inputs:\n",
    "      inputs: list of lenght time steps for rnn inputs.\n",
    "      num_units: number of network units.\n",
    "      num_classes: network output classes.\n",
    "      activation: activation function to use for cell (default tanh).\n",
    "    \"\"\"\n",
    "    \n",
    "    self.weights = {}\n",
    "    self.biases = {}\n",
    "    with tf.variable_scope(\"rnn\"):\n",
    "      with tf.variable_scope(\"internal\"):\n",
    "        self.cell = tf.nn.rnn_cell.GRUCell(\n",
    "          num_units=num_units, activation=activation)\n",
    "        \n",
    "        self.outputs, self.state = tf.contrib.rnn.static_rnn(\n",
    "          cell=self.cell, inputs=inputs, dtype=tf.float32)\n",
    "      with tf.variable_scope(\"output\"):\n",
    "        self.weights[\"out\"] = tf.get_variable(name=\"w\",\n",
    "                        shape=(num_units, num_classes),\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        \n",
    "        self.biases[\"out\"] = tf.get_variable(name=\"b\",\n",
    "                        shape=(num_classes),\n",
    "                        initializer=tf.zeros_initializer())\n",
    "    for v in self.cell.trainable_variables:\n",
    "      name = v.name\n",
    "      if \"gates/kernel\" in name:\n",
    "        self.weights[\"gates\"] = v\n",
    "      elif \"gates/bias\" in name:\n",
    "        self.biases[\"gates\"] = v\n",
    "\n",
    "      elif \"candidate/kernel\" in name:\n",
    "        self.weights[\"candidate\"] = v\n",
    "      elif \"candidate/bias\" in name:\n",
    "        self.biases[\"candidate\"] = v\n",
    "\n",
    "    # compute logits at each time step\n",
    "    self.logits_list = []\n",
    "    for output in self.outputs:\n",
    "      self.logits_list.append(\n",
    "        tf.matmul(output, self.weights[\"out\"]) + self.biases[\"out\"]) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-650099426339>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/gamal/git_local_repo/playground/data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/Users/gamal/git_local_repo/playground/data/mnist\"\n",
    "data_provider_train = mnist_provider(data_dir, split='train')\n",
    "data_provider_valid = mnist_provider(data_dir, split='valid')\n",
    "data_provider_test = mnist_provider(data_dir, split='test')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "  x = tf.placeholder(dtype=tf.float32, shape=(None, T, in_dim))\n",
    "  one_hot_labels = tf.placeholder(dtype=tf.float32, shape=(None, num_classes))\n",
    "  # convert in put to a list of len number of time points\n",
    "  x_t = tf.unstack(x, T, 1)\n",
    "  \n",
    "  # model\n",
    "  rnn_model = RNN(inputs=x_t, num_units=num_units, num_classes=num_classes)\n",
    "  logits = rnn_model.logits_list[-1]\n",
    "  \n",
    "  # accuracy metric\n",
    "  top1_op = tf.nn.in_top_k(logits, tf.argmax(one_hot_labels, 1), 1)\n",
    "  accuracy = tf.reduce_mean(tf.cast(top1_op, dtype=tf.float32))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                               labels=one_hot_labels)\n",
    "  )\n",
    "  opt = tf.train.AdamOptimizer(learning_rate=init_lr)\n",
    "  \n",
    "  train_op = opt.minimize(loss)\n",
    "  \n",
    "  init_op = tf.global_variables_initializer()\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "  saver = tf.train.Saver(tf.global_variables())\n",
    "  train_dir = \"/Users/gamal/git_local_repo/playground/experiments/pixel_rnn/train\"\n",
    "  if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: (train loss: 2.303) (train accuracy: 0.023)\n",
      "iter 500: (train loss: 2.302) (train accuracy: 0.125)\n",
      "iter 1000: (train loss: 2.299) (train accuracy: 0.109)\n",
      "iter 1500: (train loss: 2.280) (train accuracy: 0.113)\n",
      "iter 2000: (train loss: 2.290) (train accuracy: 0.172)\n",
      "iter 2500: (train loss: 2.244) (train accuracy: 0.229)\n",
      "iter 3000: (train loss: 1.984) (train accuracy: 0.230)\n",
      "iter 3500: (train loss: 2.301) (train accuracy: 0.113)\n",
      "iter 4000: (train loss: 2.298) (train accuracy: 0.109)\n",
      "iter 4500: (train loss: 2.196) (train accuracy: 0.186)\n",
      "iter 5000: (train loss: 2.032) (train accuracy: 0.227)\n",
      "iter 5500: (train loss: 1.844) (train accuracy: 0.186)\n",
      "iter 6000: (train loss: 1.771) (train accuracy: 0.299)\n",
      "iter 6500: (train loss: 1.464) (train accuracy: 0.543)\n",
      "iter 7000: (train loss: 1.031) (train accuracy: 0.613)\n",
      "iter 7500: (train loss: 0.806) (train accuracy: 0.715)\n",
      "iter 8000: (train loss: 0.700) (train accuracy: 0.760)\n",
      "iter 8500: (train loss: 0.554) (train accuracy: 0.801)\n",
      "iter 9000: (train loss: 0.455) (train accuracy: 0.842)\n",
      "iter 9500: (train loss: 0.425) (train accuracy: 0.834)\n",
      "iter 10000: (train loss: 0.459) (train accuracy: 0.861)\n",
      "iter 10500: (train loss: 0.285) (train accuracy: 0.908)\n",
      "iter 11000: (train loss: 0.229) (train accuracy: 0.936)\n",
      "iter 11500: (train loss: 0.182) (train accuracy: 0.943)\n",
      "iter 12000: (train loss: 0.105) (train accuracy: 0.969)\n",
      "iter 12500: (train loss: 0.162) (train accuracy: 0.936)\n",
      "iter 13000: (train loss: 0.151) (train accuracy: 0.947)\n",
      "iter 13500: (train loss: 0.046) (train accuracy: 0.988)\n",
      "iter 14000: (train loss: 0.089) (train accuracy: 0.975)\n",
      "iter 14500: (train loss: 0.084) (train accuracy: 0.975)\n",
      "iter 15000: (train loss: 0.073) (train accuracy: 0.975)\n",
      "iter 15500: (train loss: 0.093) (train accuracy: 0.980)\n",
      "iter 16000: (train loss: 0.087) (train accuracy: 0.977)\n",
      "iter 16500: (train loss: 0.075) (train accuracy: 0.975)\n",
      "iter 17000: (train loss: 0.043) (train accuracy: 0.986)\n",
      "iter 17500: (train loss: 0.036) (train accuracy: 0.984)\n",
      "iter 18000: (train loss: 0.082) (train accuracy: 0.977)\n",
      "iter 18500: (train loss: 0.033) (train accuracy: 0.990)\n",
      "iter 19000: (train loss: 0.046) (train accuracy: 0.984)\n",
      "iter 19500: (train loss: 0.050) (train accuracy: 0.984)\n",
      "iter 20000: (train loss: 0.086) (train accuracy: 0.975)\n",
      "iter 20500: (train loss: 0.021) (train accuracy: 0.992)\n",
      "iter 21000: (train loss: 0.044) (train accuracy: 0.984)\n",
      "iter 21500: (train loss: 0.027) (train accuracy: 0.994)\n",
      "iter 22000: (train loss: 0.077) (train accuracy: 0.980)\n",
      "iter 22500: (train loss: 0.029) (train accuracy: 0.994)\n",
      "iter 23000: (train loss: 0.041) (train accuracy: 0.986)\n",
      "iter 23500: (train loss: 0.052) (train accuracy: 0.988)\n",
      "iter 24000: (train loss: 0.032) (train accuracy: 0.990)\n",
      "iter 24500: (train loss: 0.012) (train accuracy: 0.994)\n",
      "iter 25000: (train loss: 0.015) (train accuracy: 0.994)\n",
      "iter 25500: (train loss: 0.016) (train accuracy: 0.994)\n",
      "iter 26000: (train loss: 0.022) (train accuracy: 0.990)\n",
      "iter 26500: (train loss: 0.028) (train accuracy: 0.990)\n",
      "iter 27000: (train loss: 0.030) (train accuracy: 0.994)\n",
      "iter 27500: (train loss: 0.014) (train accuracy: 0.992)\n",
      "iter 28000: (train loss: 0.024) (train accuracy: 0.992)\n",
      "iter 28500: (train loss: 0.019) (train accuracy: 0.994)\n",
      "iter 29000: (train loss: 0.004) (train accuracy: 1.000)\n",
      "iter 29500: (train loss: 0.002) (train accuracy: 1.000)\n",
      "iter 30000: (train loss: 0.023) (train accuracy: 0.992)\n",
      "iter 30500: (train loss: 0.030) (train accuracy: 0.994)\n",
      "iter 31000: (train loss: 0.009) (train accuracy: 0.996)\n",
      "iter 31500: (train loss: 0.007) (train accuracy: 0.998)\n",
      "iter 32000: (train loss: 0.008) (train accuracy: 0.998)\n",
      "iter 32500: (train loss: 0.015) (train accuracy: 0.992)\n",
      "iter 33000: (train loss: 0.010) (train accuracy: 0.994)\n",
      "iter 33500: (train loss: 0.002) (train accuracy: 1.000)\n",
      "iter 34000: (train loss: 0.005) (train accuracy: 0.998)\n",
      "iter 34500: (train loss: 0.011) (train accuracy: 0.996)\n",
      "iter 35000: (train loss: 0.004) (train accuracy: 0.998)\n",
      "iter 35500: (train loss: 0.010) (train accuracy: 0.998)\n",
      "iter 36000: (train loss: 0.003) (train accuracy: 0.998)\n",
      "iter 36500: (train loss: 0.001) (train accuracy: 1.000)\n",
      "iter 37000: (train loss: 0.001) (train accuracy: 1.000)\n",
      "iter 37500: (train loss: 0.001) (train accuracy: 1.000)\n",
      "iter 38000: (train loss: 0.004) (train accuracy: 0.998)\n",
      "iter 38500: (train loss: 0.001) (train accuracy: 1.000)\n",
      "iter 39000: (train loss: 0.037) (train accuracy: 0.988)\n",
      "iter 39500: (train loss: 0.001) (train accuracy: 1.000)\n",
      "iter 40000: (train loss: 0.008) (train accuracy: 0.996)\n",
      "iter 40500: (train loss: 0.007) (train accuracy: 0.996)\n",
      "iter 41000: (train loss: 0.008) (train accuracy: 0.996)\n",
      "iter 41500: (train loss: 0.004) (train accuracy: 0.998)\n",
      "iter 42000: (train loss: 0.002) (train accuracy: 0.998)\n",
      "iter 42500: (train loss: 0.005) (train accuracy: 1.000)\n",
      "iter 43000: (train loss: 0.005) (train accuracy: 0.998)\n",
      "iter 43500: (train loss: 0.003) (train accuracy: 1.000)\n",
      "iter 44000: (train loss: 0.000) (train accuracy: 1.000)\n",
      "iter 44500: (train loss: 0.000) (train accuracy: 1.000)\n",
      "iter 45000: (train loss: 0.007) (train accuracy: 0.996)\n",
      "iter 45500: (train loss: 0.002) (train accuracy: 1.000)\n",
      "iter 46000: (train loss: 0.012) (train accuracy: 0.996)\n",
      "iter 46500: (train loss: 0.001) (train accuracy: 1.000)\n",
      "iter 47000: (train loss: 0.000) (train accuracy: 1.000)\n",
      "iter 47500: (train loss: 0.000) (train accuracy: 1.000)\n",
      "iter 48000: (train loss: 0.000) (train accuracy: 1.000)\n",
      "iter 48500: (train loss: 0.000) (train accuracy: 1.000)\n",
      "iter 49000: (train loss: 0.000) (train accuracy: 1.000)\n",
      "iter 49500: (train loss: 0.000) (train accuracy: 1.000)\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for i in xrange(max_iter):\n",
    "      imgs, lbls = data_provider_train.next_batch(\n",
    "        batch_size=batch_size)\n",
    "      _, ls, acc = sess.run(\n",
    "        (train_op, loss, accuracy),\n",
    "        feed_dict={x: imgs.reshape((-1, 28*28, 1)),\n",
    "                   one_hot_labels: lbls}\n",
    "      )\n",
    "      if i % 500 == 0:\n",
    "        saver.save(sess, os.path.join(train_dir, 'rnn_model.ckpt'), global_step=i)\n",
    "        print(\n",
    "          \"iter %d: (train loss: %.3f) (train accuracy: %.3f)\" \n",
    "          %(i, ls, acc)\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/gamal/git_local_repo/playground/experiments/pixel_rnn/train/rnn_model.ckpt-49500\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "with g.as_default():\n",
    "  with tf.Session() as sess:\n",
    "    saver.restore(sess, os.path.join(train_dir, 'rnn_model.ckpt-49500'))\n",
    "    num_batches = data_provider_test.mnist_data.num_examples // batch_size\n",
    "    for _ in xrange(num_batches):\n",
    "      imgs, lbls = data_provider_test.next_batch(\n",
    "          batch_size=batch_size)\n",
    "      test_acc += sess.run(accuracy, feed_dict={\n",
    "        x: imgs.reshape((-1, 28*28, 1)),\n",
    "        one_hot_labels: lbls}) / num_batches\n",
    "    print(\n",
    "      \"test accuracy: %.3f)\" \n",
    "      %(test_acc)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
